{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14094,"status":"ok","timestamp":1675512785523,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"},"user_tz":-60},"id":"p2FuW3jAmMjf","outputId":"e00fb449-abcc-48f2-f60f-a1e62124eeba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n","Collecting tensorflow-gpu\n","  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n","Collecting python_version>\"3.7\"\n","  Downloading python_version-0.0.2-py2.py3-none-any.whl (3.4 kB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.12.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n","Building wheels for collected packages: tensorflow-gpu\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for tensorflow-gpu (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for tensorflow-gpu\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for tensorflow-gpu\n","Failed to build tensorflow-gpu\n","Installing collected packages: python_version, tensorflow-gpu\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for tensorflow-gpu\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Running setup.py install for tensorflow-gpu ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while trying to install package.\n","\u001b[31m╰─>\u001b[0m tensorflow-gpu\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"]}],"source":["!pip install tensorflow tensorflow-gpu opencv-python matplotlib"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1735,"status":"ok","timestamp":1675512818129,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"},"user_tz":-60},"id":"bOuDZOipnLlO","outputId":"1e38005c-91bc-4854-c5e1-7e05b84206ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import cv2\n","import tensorflow as tf\n","import cv2\n","import json\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_CE0rjvwnfuO","executionInfo":{"status":"ok","timestamp":1675512820305,"user_tz":-60,"elapsed":184,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"}}},"outputs":[],"source":["# Avoid OOM errors by setting GPU Memory Consumption Growth\n","gpus = tf.config.experimental.list_physical_devices('TPU')\n","for gpu in gpus: \n","    tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"markdown","source":["# Funciones para cargar las imagenes y annotaciones\n","\n","Estas funciones tambien se encargaran de normalizar los puntos (dividiendo por /255) para asi que todos los valores esten en un mismo rango y nuestro modelo funcione mejor, ademas de redimensionar las imagenes a la resolucion compatible con el modelo (512x512)"],"metadata":{"id":"k4khs0u6U7hr"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"W3KWaNLSntWw","executionInfo":{"status":"ok","timestamp":1675512832145,"user_tz":-60,"elapsed":10723,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"}}},"outputs":[],"source":["def load_image(x): \n","    byte_img = tf.io.read_file(x)\n","    img = tf.io.decode_jpeg(byte_img)\n","    return img\n","\n","train_images = tf.data.Dataset.list_files(r'/content/drive/MyDrive/EyePosition/dataset_format/train_1/train_1/*.jpg', shuffle=False)\n","train_images = train_images.map(load_image)\n","train_images = train_images.map(lambda x: tf.image.resize(x, (512,512)))\n","train_images = train_images.map(lambda x: x/255)\n","\n","test_images = tf.data.Dataset.list_files(r'/content/drive/MyDrive/EyePosition/dataset_format/train_2/train_2/*.jpg', shuffle=False)\n","test_images = test_images.map(load_image)\n","test_images = test_images.map(lambda x: tf.image.resize(x, (512,512)))\n","test_images = test_images.map(lambda x: x/255)\n","\n","val_images = tf.data.Dataset.list_files(r'/content/drive/MyDrive/EyePosition/dataset_format/train_3/train_3/*.jpg', shuffle=False)\n","val_images = val_images.map(load_image)\n","val_images = val_images.map(lambda x: tf.image.resize(x, (512,512)))\n","val_images = val_images.map(lambda x: x/255)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"n5d5VOu1n_dk","executionInfo":{"status":"ok","timestamp":1675512840037,"user_tz":-60,"elapsed":7896,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"}}},"outputs":[],"source":["def load_labels(label_path):\n","    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n","        label = json.load(f)\n","    return [label['keypoints']]\n","\n","train_labels = tf.data.Dataset.list_files(r'/content/drive/MyDrive/EyePosition/dataset_format/train_1/annotation/*.json', shuffle=False)\n","train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n","\n","test_labels = tf.data.Dataset.list_files(r'/content/drive/MyDrive/EyePosition/dataset_format/train_2/annotation/*.json', shuffle=False)\n","test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n","\n","val_labels = tf.data.Dataset.list_files(r'/content/drive/MyDrive/EyePosition/dataset_format/train_3/annotation/*.json', shuffle=False)\n","val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"OHYK9FzNoTH4","executionInfo":{"status":"ok","timestamp":1675512840038,"user_tz":-60,"elapsed":15,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"}}},"outputs":[],"source":["train = tf.data.Dataset.zip((train_images, train_labels))\n","train = train.batch(8)\n","train = train.prefetch(4)\n","\n","test = tf.data.Dataset.zip((test_images, test_labels))\n","test = test.batch(8)\n","test = test.prefetch(4)\n","\n","val = tf.data.Dataset.zip((val_images, val_labels))\n","val = val.batch(8)\n","val = val.prefetch(4)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"8sp3eW7TxSTe","executionInfo":{"status":"ok","timestamp":1675512856778,"user_tz":-60,"elapsed":16753,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"}},"colab":{"base_uri":"https://localhost:8080/","height":639,"output_embedded_package_id":"1_HaV4a5GntE1RAY88N7QhYGfIHChILsx"},"outputId":"144fcd37-01c8-49af-fa33-dd62cc80eef0"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["data_samples = train.as_numpy_iterator()\n","res = data_samples.next()\n","fig, ax = plt.subplots(ncols=4, figsize=(50,50))\n","for idx in range(4): \n","    sample_image = res[0][idx]\n","    sample_coords = res[1][0][idx]\n","    for i in range(0,79,2):\n","      cv2.circle(sample_image, [int(sample_coords[i]*512), int(sample_coords[i+1]*512)], 2, (255,0,0), -1)\n","    \n","    \n","    ax[idx].imshow(sample_image)"]},{"cell_type":"markdown","source":["# Primer modelo (ResNet)\n","\n","Para alcanzar nuestro objetivo vamos a usar un PreTrained Model para asi ahorrar un poco de tiempo a la hora de entrenar el modelo. En este caso se ha usado el modelo ResNet y se ha modificado para que sea compatible con el numero de puntos que tenemos de output en nuestro caso."],"metadata":{"id":"5nL5WJkwVhpG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZX8wXD81J5r","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea5302a0-2594-43d7-ddd1-7e96fdf892e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","234545216/234545216 [==============================] - 1s 0us/step\n","Epoch 1/200\n","125/125 [==============================] - 403s 3s/step - loss: 0.0455 - val_loss: 0.1090\n","Epoch 2/200\n","125/125 [==============================] - 158s 1s/step - loss: 0.0078 - val_loss: 0.0257\n","Epoch 3/200\n","125/125 [==============================] - 156s 1s/step - loss: 0.0057 - val_loss: 0.0118\n","Epoch 4/200\n","125/125 [==============================] - 154s 1s/step - loss: 0.0029 - val_loss: 0.0027\n","Epoch 5/200\n","125/125 [==============================] - 155s 1s/step - loss: 0.0020 - val_loss: 0.0020\n","Epoch 6/200\n","125/125 [==============================] - 155s 1s/step - loss: 0.0021 - val_loss: 0.0018\n","Epoch 7/200\n","125/125 [==============================] - ETA: 0s - loss: 0.0018"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Conv2D, Reshape, Dropout\n","from tensorflow.keras.applications import ResNet152V2\n","\n","model = Sequential([\n","    Input(shape=(512,512,3)), \n","    ResNet152V2(include_top=False, input_shape=(512,512,3)),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    Conv2D(256, 3, 2, padding='same', activation='relu'),\n","    Conv2D(256, 2, 2, activation='relu'),\n","    Dropout(0.05),\n","    Conv2D(80, 2, 2),\n","    Conv2D(80, 2, 1),\n","    Reshape((80,))\n","])\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0007)\n","loss = tf.keras.losses.MeanSquaredError()\n","\n","model.compile(optimizer, loss)\n","\n","hist = model.fit(train, epochs=200, validation_data=val)"]},{"cell_type":"code","source":["model.save('/content/drive/MyDrive/eyeposition.h5')"],"metadata":{"id":"JJS-hpHmAqol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","model = load_model('/content/drive/MyDrive/eyeposition.h5')\n","test_data = test.as_numpy_iterator()\n","test_sample = test_data.next()\n","yhat = model.predict(test_sample[0])\n","fig, ax = plt.subplots(ncols=3, figsize=(20,20))\n","for idx in range(3): \n","    sample_image = test_sample[0][idx]\n","    sample_coords = yhat[idx]\n","    \n","    for i in range(0,79,2):\n","      cv2.circle(sample_image, [int(sample_coords[i]*512), int(sample_coords[i+1]*512)], 2, (255,0,0), -1)\n","    \n","    ax[idx].imshow(sample_image)"],"metadata":{"id":"DK-O0OWizaO5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_model('/content/drive/MyDrive/eyeposition.h5')\n","hist = model.fit(train, epochs=100, validation_data=val)"],"metadata":{"id":"j5WR6PtXSCC5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Al comprobar el funcionamiento del modelo se ve que funciona correctamente, solo que es demasiado lento para nuestra aplicacion. Tras probar el modelo en tiempo real en mi ordenador personal se consigue una media de 2 segundos para procesar cada fotograma de video, es decir, 0.5 fps lo cual no es suficiente.\n","\n","Como alternativa se puede intentar usar otro PreTrained Model que no sea ResNet. Accediendo a ModelZoo de TensorFlow se encuentra el Modelo \"CenterNet MobileNetV2 FPN Keypoints 512x512\" con las siguientes caracteristicas:\n","\n","\n","| Model Name | Speed (ms) | COCO mAP |\n","| --- | --- | --- |\n","| CenterNet MobileNetV2 FPN Keypoints 512x512 | 6 | 41.7 |"],"metadata":{"id":"ilgAKTZ0Wuc5"}},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","import cv2\n","import numpy as np\n","\n","model = load_model('/content/drive/MyDrive/eyeposition.h5')\n","\n","cap = cv2.VideoCapture(0)\n","while cap.isOpened():\n","    _ , frame = cap.read()\n","    \n","    h,w,c = frame.shape\n","    rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    resized = cv2.resize(rgb_img, (512,512))\n","    \n","    yhat = model.predict(np.expand_dims(resized/255,0))\n","    sample_coords = yhat[0]\n","    \n","    for i in range(0,79,2):\n","        cv2.circle(frame, [int(sample_coords[i]*w), int(sample_coords[i+1]*h)], 2, (0,255,0), -1)\n","    \n","    cv2.imshow('EyeTrack', frame)\n","    \n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"B0uU3YY_vp2c"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1gSBwD8CqXmUSUv-4MQME473xccsRKV7u","authorship_tag":"ABX9TyMq3iiX7fzesVdpJUr7sXJh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"premium"},"nbformat":4,"nbformat_minor":0}