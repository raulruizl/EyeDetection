{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11105,"status":"ok","timestamp":1675511198708,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"},"user_tz":-60},"id":"To8YC87L8QLw","outputId":"77faf15d-0537-4b6b-e286-0a1ac86a061c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Preprocesado de los datos.\n","\n","Nuestro objetivo es que el modelo a realizar detecte donde estan los ojos cuando le demos una foto. Para ello lo primero que necesitamos son datos. La Universidad de Illinois nos ofrece el dataset al que llaman <a href=\"http://www.ifp.illinois.edu/~vuongle2/helen/\">Helen Dataset</a>.. Este contiene 2000 imagenes con anotaciones de las principales areas faciales, en la que se incluyen los ojos.\n","\n","Debemos \"limpiar\" el dataset para solo quedarnos con los datos que corresponden a los ojos y transforman los datos al formato que queremos."],"metadata":{"id":"46HRkNErMyJK"}},{"cell_type":"markdown","source":["# Cargar las imagenes"],"metadata":{"id":"grUZqNM2PqiT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUDcGbIWt5CG","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1675511271291,"user_tz":-60,"elapsed":72590,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"}},"outputId":"8d462f64-89ee-4e3e-8636-507a00c9a1e1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     index        x        y       file_id\n","101    101   880.28  1014.39  2397601939_1\n","141    141  1199.25   903.11  2685003351_1\n","166    166  1280.36   466.77  2198286445_1"],"text/html":["\n","  <div id=\"df-cecba8a0-9681-445d-b360-0dc436ae3373\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>file_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>101</th>\n","      <td>101</td>\n","      <td>880.28</td>\n","      <td>1014.39</td>\n","      <td>2397601939_1</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>141</td>\n","      <td>1199.25</td>\n","      <td>903.11</td>\n","      <td>2685003351_1</td>\n","    </tr>\n","    <tr>\n","      <th>166</th>\n","      <td>166</td>\n","      <td>1280.36</td>\n","      <td>466.77</td>\n","      <td>2198286445_1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cecba8a0-9681-445d-b360-0dc436ae3373')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cecba8a0-9681-445d-b360-0dc436ae3373 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cecba8a0-9681-445d-b360-0dc436ae3373');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}],"source":["%matplotlib inline\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","import os\n","import matplotlib.pyplot as plt\n","from skimage.io import imread\n","import json\n","import cv2\n","helen_dir = '/content/drive/MyDrive/EyePosition/dataset/'\n","def read_annot_file(in_path):\n","    with open(in_path, 'r') as f:\n","        file_id = f.readline().strip()\n","    out_df = pd.read_csv(in_path, skiprows=1, header=None)\n","    out_df.columns = ['x', 'y']\n","    out_df['file_id'] = file_id\n","    return out_df\n","\n","annot_df = pd.concat([\n","    read_annot_file(c_path).reset_index()\n","    for c_path in \n","    glob(os.path.join(helen_dir, 'annotation', '*', '*'))\n","])\n","annot_df.sample(3)"]},{"cell_type":"markdown","source":["# Cargar las anotaciones"],"metadata":{"id":"HgV6aNlnQnXL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjJ9gMPcwxor"},"outputs":[],"source":["all_image_dict = {os.path.splitext(f)[0]: os.path.join(p, f) \n","              for p, _, files in os.walk(helen_dir) \n","              for f in files if f.upper().endswith('JPG')}\n","\n","annot_df['path'] = annot_df['file_id'].map(all_image_dict.get)\n","annot_df.dropna(inplace=True)"]},{"cell_type":"markdown","source":["Se observa que los datos usan el formato FUT estandar que consiste en lo siquiente:\n","<ul>\n","  <li>Linea de la cara: 41 puntos</li>\n","  <li>Linea de la nariz: 17 puntos</li>\n","  <li>Linea de los ojos: 20 puntos (por cada ojo)</li>\n","  <li>Linea de las cejas: 20 puntos (por cada ojo)</li>\n","  <li>Linea de la boca: 28 puntos (por cada labio)</li>\n","</ul>\n","\n","Teniendo en cuenta esto es dificil poner una etiqueta a cada punto dependendiendo de a que parte de la cara corresponde. Es lo que el codigo de abajo hace:"],"metadata":{"id":"iouLeeLOQw3l"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1bsqBkXzCSLdootXrobndlUuVslvZXXyF"},"executionInfo":{"elapsed":27248,"status":"ok","timestamp":1666469832031,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"},"user_tz":-120},"id":"SAjSTyDWwXDW","outputId":"e0bbb5c9-4d35-46b6-e685-81552148b921"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["fig, m_axs = plt.subplots(3, 3, figsize = (30, 30))\n","marker_id = ['face', 'nose', 'mouth_inner', 'mouth_outer', 'r_eye', 'l_eye', 'r_eyebrow', 'l_eyebrow']\n","marker_split = np.cumsum([0, 41, 17, 28, 28, 20, 20, 20, 20])\n","marker_dict = {marker_id[i]: (marker_split[i], marker_split[i+1]) for i in range(len(marker_split)-1)}\n","for c_ax, (c_path, c_rows) in zip(m_axs.flatten(), annot_df.groupby('path')):\n","    img = imread(c_path)\n","    c_ax.imshow(img)\n","    for label, (start, end) in marker_dict.items():\n","        n_rows = c_rows.query(f'index>={start} and index<={end}')\n","        c_ax.plot(n_rows['x'], n_rows['y'], '.', label=label)\n","    c_ax.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1666469832032,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"},"user_tz":-120},"id":"9MMf3tbRymLB","outputId":"c50e1e97-d06e-4673-8709-e6301b81900d"},"outputs":[{"data":{"text/plain":["face           82000\n","mouth_inner    56000\n","mouth_outer    56000\n","r_eye          40000\n","l_eye          40000\n","r_eyebrow      40000\n","l_eyebrow      40000\n","nose           34000\n","Name: body_part, dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["\n","point_map = {i: [k for k, (n,x) in marker_dict.items() if n<=i<x] \n"," for i in range(annot_df['index'].max()+1) }\n","annot_df['body_part'] = annot_df['index'].map(lambda x: point_map.get(x)[0])\n","annot_df['body_part'].value_counts()"]},{"cell_type":"markdown","source":["Una vez hecho esto gracias a las facilidades que nos da la libreria pandas se pueden filtrar los puntos para asi solo quedarnos con los que necesitamos, en nuestro caso los ojos."],"metadata":{"id":"KaBh7QE6RqU8"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ij8fYV7C9-hiURawi1GJuWX3BenDIMsV"},"executionInfo":{"elapsed":16806,"status":"ok","timestamp":1666469848824,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"},"user_tz":-120},"id":"NsSeB81kzmP8","outputId":"aed0ae27-88e2-4a0b-cc34-7fe2bf76b4e5"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["filt_df = annot_df[annot_df['body_part'].isin(['l_eye', 'r_eye'])]\n","fig, m_axs = plt.subplots(3, 3, figsize = (30, 30))\n","for c_ax, (c_path, c_rows) in zip(m_axs.flatten(), filt_df.groupby('path')):\n","    img = imread(c_path)\n","    c_ax.imshow(img)\n","    for label, (start, end) in marker_dict.items():\n","        n_rows = c_rows.query(f'index>={start} and index<={end}')\n","        c_ax.plot(n_rows['x'], n_rows['y'], '.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1666469848825,"user":{"displayName":"Raúl Ruiz","userId":"08813834134020465242"},"user_tz":-120},"id":"_V4rw7llelu-","outputId":"ff0e280e-62ae-4bc5-a045-9b0539d2eac1"},"outputs":[{"data":{"text/plain":["RangeIndex(start=0, stop=40, step=1)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["file_id = []\n","for file in filt_df['file_id']:\n","  if file not in file_id:\n","      file_id.append(file)\n","len(file_id)\n","\n","df = filt_df[ filt_df.file_id == file_id[0]]\n","df = df.reset_index()\n","df['body_part'].value_counts()\n","df.index"]},{"cell_type":"markdown","source":["Por ultimo, vamos a transformar los datos en un formato en el que me siento mas comodo, ya que he trabajado previamente con el. Se trata de guardar los puntos en un archivo json de la siguiente forma:\n","\n","{\n","\n","  \"image\": \"filename.jpg\",\n","\n","  \"class\": [1,1],\n","  \n","  \"keypoints\": (Puntos de los ojos)\n","\n","}\n","\n","Tras esto se guardan todos los puntos en su correspondiente archivo json y ya estarian todos los datos preparados para entrenar el modelo"],"metadata":{"id":"zVLDtchVSa-4"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EPeBNsh8uFYg"},"outputs":[],"source":["keypoints = []\n","for file in file_id:\n","\n","  df = filt_df[filt_df.file_id == file]\n","  df = df.drop('index',axis=1)\n","  df = df.reset_index()\n","  img = cv2.imread('/content/drive/MyDrive/img/{}.jpg'.format(file))\n","  \n","  h,w,c = img.shape\n","  #for i in df_left.index:\n","    \n","    #   row = df_left.iloc[i]\n","    #  keypoints.append(row['x'])\n","    #   keypoints.append(row['y'])\n","  for i in range(0,len(df.index)):\n","    \n","      row = df.iloc[i]\n","      keypoints.append(row['x']/w)\n","      keypoints.append(row['y']/h)\n","\n","  if len(keypoints) > 0:\n","    js = { \"image\": \"{}.jpg\".format(file), \"class\" : [1,1],\"keypoints\": keypoints}\n","    with open('/content/drive/MyDrive/annotation/{}.json'.format(file), 'w') as f:\n","      json.dump(js, f, indent=2)\n","    keypoints.clear()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZa8TPLD-HNP"},"outputs":[],"source":["import cv2\n","import json\n","import time\n","from google.colab.patches import cv2_imshow\n","with open(r'/content/drive/MyDrive/EyePosition/dataset_format/train_1/annotation/100040721_1.json',) as f:\n","  file = json.load(f)\n","  keypoints = file['keypoints']\n","\n","img = cv2.imread('/content/drive/MyDrive/EyePosition/dataset_format/train_1/train_1/100040721_1.jpg')\n","h,w,c = img.shape\n","print(len(keypoints))\n","for i in range(0,len(keypoints)-1,2):\n","\n","    cv2.circle(img, [int(keypoints[i])*w, int(keypoints[i+1])*h], 2, (255,0,0), -1)\n","\n","cv2_imshow(img)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALg2mcHQXiPR"},"outputs":[],"source":["!zip -r /content/annotation.zip /content/drive/MyDrive/annotation\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"14ZACwLT7XxkEgLUfcixFba3S4wVu0eLf","authorship_tag":"ABX9TyM5W1SzzudKoemF5c75Wa8k"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}